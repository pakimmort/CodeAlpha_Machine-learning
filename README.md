# ğŸ“Š Credit Scoring Model using Machine Learning

## ğŸ“Œ Project Overview
This project focuses on building a **Credit Scoring Model** to predict an individual's **creditworthiness** based on past financial and behavioral data. The model helps financial institutions assess the risk of loan default and make data-driven lending decisions.

Multiple **classification algorithms** are implemented and compared to identify the most effective model.

---

## ğŸ¯ Objective
To predict whether an individual is:
- **Creditworthy (Low Risk)** â†’ `1`
- **Not Creditworthy (High Risk)** â†’ `0`

using historical financial data.

---

## ğŸ—‚ï¸ Dataset Description
The dataset contains financial attributes such as:

- `income` â€“ Monthly or annual income  
- `debt` â€“ Total outstanding debt  
- `credit_utilization` â€“ Percentage of credit used  
- `payment_history` â€“ Record of late/missed payments  
- `employment_length` â€“ Years of employment  
- `credit_history_length` â€“ Length of credit history  
- `target` â€“ Creditworthiness label (0 or 1)

> âš ï¸ Dataset can be replaced with any real-world credit dataset.

---

## ğŸ› ï¸ Technologies Used
- **Python**
- **Pandas & NumPy** â€“ Data handling
- **Matplotlib & Seaborn** â€“ Visualization
- **Scikit-learn** â€“ Machine Learning models & evaluation

---

## ğŸ” Methodology

### 1ï¸âƒ£ Data Preprocessing
- Handling missing values using **median imputation**
- Feature scaling using **StandardScaler**
- Train-test split with stratification

---

### 2ï¸âƒ£ Feature Engineering
- Creation of meaningful financial ratios
- Removal of irrelevant or redundant features
- Improved model interpretability

---

### 3ï¸âƒ£ Models Implemented
- **Logistic Regression**
- **Decision Tree Classifier**
- **Random Forest Classifier**

---

### 4ï¸âƒ£ Model Training
- 80% Training data
- 20% Testing data
- Random state fixed for reproducibility

---

## ğŸ“ˆ Evaluation Metrics
The models are evaluated using:

- **Accuracy**
- **Precision**
- **Recall**
- **F1-Score**
- **ROC-AUC Score**
- **Confusion Matrix**
- **ROC Curve**

> ğŸ”‘ Recall is prioritized to reduce false approvals of high-risk applicants.

---

## ğŸ“Š Results & Comparison
- Performance of all three models is compared
- ROC curves are plotted for visual comparison
- **Random Forest** generally performs best due to ensemble learning

---

## ğŸ” Feature Importance
For tree-based models, feature importance is extracted to identify the most influential financial factors affecting credit risk.

---

## ğŸ“ Project Structure
Credit-Scoring-Model/
â”‚
â”œâ”€â”€ credit_data.csv
â”œâ”€â”€ credit_scoring_model.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
